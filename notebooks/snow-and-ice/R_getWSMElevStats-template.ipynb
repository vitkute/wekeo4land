{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5072f2e4",
   "metadata": {},
   "source": [
    "<img src='../../media/common/LogoWekeo_Copernicus_RGB_0.png' align='left' height='96px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf29cd",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd19732",
   "metadata": {},
   "source": [
    "# Analyzing Wet Snow Extent from SWS Time Series Based on Altitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed47b4",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Before we begin, we need to prepare our environment by installing and importing the necessary R packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(terra)\n",
    "library(fs)\n",
    "library(ggplot2)\n",
    "\n",
    "library(magrittr)\n",
    "library(dplyr)\n",
    "library(scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57545f1",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d727a0e",
   "metadata": {},
   "source": [
    "#### Function to Open and Read GeoTIFF Files, Assuming Downloaded Products Have Already Been Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "read_tif <- function(file_tif) {\n",
    "  ds <- rast(file_tif)\n",
    "  \n",
    "  proj <- crs(ds)\n",
    "  width <- ncol(ds)\n",
    "  height <- nrow(ds)\n",
    "  count <- nlyr(ds)\n",
    "  meta <- list(\n",
    "    min = minmax(ds)[1, ],\n",
    "    max = minmax(ds)[2, ],\n",
    "    mean = global(ds, fun = mean, na.rm = TRUE),\n",
    "    sd = global(ds, fun = sd, na.rm = TRUE)\n",
    "  )\n",
    "  \n",
    "  list(data = ds, width = width, height = height, count = count, meta = meta, proj = proj)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a683fa4",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a15fd",
   "metadata": {},
   "source": [
    "#### Downloading SWS and DEM Data\n",
    "\n",
    "To begin our analysis, we first need to download the necessary Snow Water Equivalent (SWS) and Digital Elevation Model (DEM) data. This can be accomplished using the HDA (Harmonized Data Access) client.  \n",
    "The SWS data provides information on the extent of wet snow, while the DEM data offers detailed elevation information for the study area.  \n",
    "By querying the HDA client with specific parameters such as dataset ID, observation period, and bounding box coordinates, we can retrieve and download the relevant datasets to our local directory for further processing and analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3b47d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hda_client <- hdar::Client$new()\n",
    "\n",
    "download_dir <- \"../../data/download/snow-and-ice/products\"\n",
    "if (!fs::dir_exists(download_dir)) {\n",
    "  fs::dir_create(download_dir)\n",
    "}\n",
    "\n",
    "query_sws <- jsonlite::toJSON(list(\n",
    "  \"dataset_id\" = \"EO:CRYO:DAT:HRSI:SWS\",\n",
    "  \"startdate\" = \"2022-11-01T01:00:00Z\",\n",
    "  \"enddate\" = \"2022-12-01T01:00:00Z\",\n",
    "  \"bbox\" = c(\n",
    "      6.213305360358289,\n",
    "      44.881040312330924,\n",
    "      6.27014257275879,\n",
    "      44.925714461959465\n",
    "  )\n",
    "), auto_unbox = TRUE)\n",
    "\n",
    "query_dem <- jsonlite::toJSON(list(\n",
    "  \"dataset_id\" = \"EO:DEM:DAT:COP-DEM_GLO-30-DTED__2023_1\",\n",
    "  \"bbox\" = c(\n",
    "      6.213305360358289,\n",
    "      44.881040312330924,\n",
    "      6.27014257275879,\n",
    "      44.925714461959465\n",
    "  )\n",
    "), auto_unbox = TRUE)\n",
    "\n",
    "tryCatch({\n",
    "    matches <- hda_client$search(query_sws, limit = 3)\n",
    "    matches$download(download_dir)\n",
    "\n",
    "    matches <- hda_client$search(query_dem, limit = 1)\n",
    "    matches$download(download_dir) \n",
    "}, error = function(e) {\n",
    "    print(e)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec7314",
   "metadata": {},
   "source": [
    "#### Organizing Downloaded Files for Analysis\n",
    "\n",
    "To facilitate the analysis, we extract the downloaded SWS and DEM files into dedicated directories. This organization ensures that all relevant data is readily accessible and systematically arranged, enhancing the efficiency of subsequent processing and analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dbe99",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "prod_dir <- \"../../data/processing/snow-and-ice/products\"\n",
    "if (!fs::dir_exists(prod_dir)) {\n",
    "  fs::dir_create(prod_dir)\n",
    "}\n",
    "\n",
    "# Find all zip files\n",
    "zip_files <- fs::dir_ls(download_dir, regexp = \"SWS_.*\\\\.zip$\")\n",
    "\n",
    "# Create SWS directory if it doesn't exist\n",
    "sws_dir <- fs::path(prod_dir, \"SWS\")\n",
    "if (!fs::dir_exists(sws_dir)) {\n",
    "    fs::dir_create(sws_dir)\n",
    "}\n",
    "\n",
    "# Unzip each file\n",
    "for (zip_file in zip_files) {\n",
    "    zip::unzip(zip_file, exdir = sws_dir)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb0728",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Find all tar files\n",
    "tar_files <- fs::dir_ls(download_dir, glob = \"*.tar\")\n",
    "\n",
    "dem_dir <- fs::path(prod_dir, \"DEM\")\n",
    "if (!fs::dir_exists(dem_dir)) {\n",
    "    fs::dir_create(dem_dir)\n",
    "}\n",
    "\n",
    "# Extract each file\n",
    "for (tar_file in tar_files) {\n",
    "    untar(tar_file, exdir = dem_dir)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc2ccb",
   "metadata": {},
   "source": [
    "#### Converting DEM from 30m to 60m Resolution\n",
    "\n",
    "In our analysis, we require a Digital Elevation Model (DEM) with a 60m resolution. However, a 60m DEM is not available for direct download from any source. The Copernicus DEM, which we are using, is available at a 30m resolution. To meet our requirements, we need to convert the 30m DEM to a 60m resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c11d7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "convert_and_resample <- function(input_dt2, output_tiff, resampled_tiff, x_res_deg, y_res_deg) {\n",
    "\n",
    "    dt2_dataset <- rast(input_dt2)\n",
    "    if (is.null(dt2_dataset)) {\n",
    "        stop(paste(\"Could not open\", input_dt2))\n",
    "    }\n",
    "\n",
    "    # Convert .dt2 to GeoTIFF\n",
    "    writeRaster(dt2_dataset, output_tiff, overwrite = TRUE, filetype = \"GTiff\")\n",
    "\n",
    "    tiff_dataset <- rast(output_tiff)\n",
    "    if (is.null(tiff_dataset)) {\n",
    "        stop(paste(\"Could not open\", output_tiff))\n",
    "    }\n",
    "\n",
    "    # Create an empty raster with the desired resolution\n",
    "    target_res <- c(x_res_deg, y_res_deg)\n",
    "    template <- rast(tiff_dataset)\n",
    "    res(template) <- target_res\n",
    "\n",
    "    # Resample the GeoTIFF to the desired resolution\n",
    "    resampled_dataset <- resample(tiff_dataset, template, method = \"bilinear\")\n",
    "\n",
    "    if (is.null(resampled_dataset)) {\n",
    "        stop(paste(\"Could not resample\", output_tiff, \"to\", resampled_tiff))\n",
    "    }\n",
    "\n",
    "    writeRaster(resampled_dataset, resampled_tiff, overwrite = TRUE, filetype = \"GTiff\")\n",
    "\n",
    "    print(paste(\"Successfully converted\", input_dt2, \"to\", resampled_tiff, \"with\", x_res_deg, \"x\", y_res_deg, \"degrees resolution.\"))\n",
    "}\n",
    "\n",
    "dt2_files <- fs::dir_ls(dem_dir, recurse = TRUE, regexp = \".*\\\\.dt2$\")\n",
    "\n",
    "resampled_dir <- fs::path(dem_dir, \"resampled\")\n",
    "if (!fs::dir_exists(resampled_dir)) {\n",
    "    fs::dir_create(resampled_dir)\n",
    "}\n",
    "\n",
    "# 60 meters to degrees conversion\n",
    "x_res_deg <- 60 / 111320\n",
    "y_res_deg <- 60 / 111320\n",
    "\n",
    "# Convert and resample .dt2 files\n",
    "for (dt2_file in dt2_files) {\n",
    "    base_name <- path_ext_remove(path_file(dt2_file))\n",
    "    output_tiff <- fs::path(resampled_dir, paste0(base_name, \".tif\"))\n",
    "    resampled_tiff <- fs::path(resampled_dir, paste0(base_name, \"_60m.tif\"))\n",
    "    convert_and_resample(dt2_file, output_tiff, resampled_tiff, x_res_deg, y_res_deg)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "files_wsm <- fs::dir_ls(fs::path(prod_dir, \"SWS\"), recurse = TRUE, regexp = \"SWS_.*_WSM\\\\.tif\")\n",
    "file_elev <- fs::dir_ls(fs::path(prod_dir, \"DEM/resampled\"), recurse = TRUE, regexp =  \".*DEM_60m\\\\.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, open and read all Wet Snow products for the mountains using the function defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "wsm_datas <- list()\n",
    "\n",
    "for (file_wsm in files_wsm) {\n",
    "  wsm_datas <- append(wsm_datas, list(read_tif(file_wsm)$data))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, open and read the elevation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "elev_data <- read_tif(file_elev[1])$data\n",
    "elev_data[is.na(elev_data)] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the data, plot the elevation data and its associated colorbar for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "nrows <- nrow(elev_data)\n",
    "ncols <- ncol(elev_data)\n",
    "\n",
    "elev_df  <- data.frame(\n",
    "  x = rep(1:nrows, each = nrows), \n",
    "  y = rep(1:ncols, times = ncols),\n",
    "  value = as.vector(elev_data[])\n",
    ")\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "ggplot(elev_df, aes(x = x, y = y, fill = value)) +\n",
    "  geom_raster() + \n",
    "  coord_fixed() +\n",
    "  scale_fill_viridis_c(breaks = seq(0, 4000, by = 500)) +\n",
    "  scale_x_continuous(breaks = seq(0, max(elev_df$x), by = 250)) +\n",
    "  scale_y_continuous(breaks = seq(0, max(elev_df$y), by = 250)) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "      legend.position = \"right\",\n",
    "      legend.direction = \"vertical\",\n",
    "      legend.justification = \"center\",\n",
    "      legend.text = element_text(size = 16),\n",
    "      legend.title = element_blank(),\n",
    "      legend.key.height = unit(2, \"cm\"),\n",
    "      axis.text = element_text(size = 14),\n",
    "      axis.title.x = element_blank(),\n",
    "      axis.title.y = element_blank(),\n",
    "  ) +\n",
    "  labs(fill = \"Elevation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, plot the first SWS product of the time series, ensuring to add a standard colorbar (not the one attached to the product)\n",
    "\n",
    "For details on the SWS product coding, please refer to the Product User Manual (https://land.copernicus.eu/user-corner/technical-library/hrsi-snow-pum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "wsm_data <- wsm_datas[[2]]\n",
    "wsm_data[is.na(wsm_data)] <- 0\n",
    "\n",
    "nrows <- nrow(wsm_data)\n",
    "ncols <- ncol(wsm_data)\n",
    "\n",
    "wsm_df  <- data.frame(\n",
    "  x = rep(1:nrows, each = nrows), \n",
    "  y = rep(1:ncols, times = ncols),\n",
    "  value = as.vector(wsm_data[])\n",
    ")\n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "ggplot(wsm_df, aes(x = x, y = y, fill = value)) +\n",
    "  geom_raster() + \n",
    "  scale_fill_viridis_c(breaks = seq(0, 250, by = 20)) +\n",
    "  coord_fixed() +\n",
    "  scale_x_continuous(breaks = seq(0, max(elev_df$x), by = 250)) +\n",
    "  scale_y_continuous(breaks = seq(0, max(elev_df$y), by = 250)) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "      legend.position = \"right\",\n",
    "      legend.direction = \"vertical\",\n",
    "      legend.justification = \"center\",\n",
    "      legend.text = element_text(size = 16),\n",
    "      legend.title = element_blank(),\n",
    "      legend.key.height = unit(2, \"cm\"),\n",
    "      axis.text = element_text(size = 14),\n",
    "      axis.title.x = element_blank(),\n",
    "      axis.title.y = element_blank(),\n",
    "  ) +\n",
    "  labs(fill = \"Elevation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the elevation intervals to be used for the analysis.\n",
    "<table><tr><td>\n",
    "Note: in this example, the elevation range covers 1000 - 4000 m a.s.l., using an altitude interval of 200 m.\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dbin <- 200\n",
    "bins <- c(seq(0, 1400, by = dbin), Inf)\n",
    "elevs <- bins[1:(length(bins)-1)] + dbin / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the elevation information for wet snow pixels and add this data to a database for all SWS products in the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "val_wet_snow <- 110\n",
    "\n",
    "hists <- list()\n",
    "for (wsm_data in wsm_datas) {\n",
    "  wsm_data[is.na(wsm_data)] <- 0\n",
    "  sel <- (values(wsm_data) == val_wet_snow)\n",
    "  \n",
    "  if (nrow(sel) < nrow(values(elev_data))) {\n",
    "    sel <- rbind(sel, matrix(FALSE, nrow(values(elev_data)) - nrow(sel), ncol(sel)))\n",
    "  }\n",
    "  elev_sel <- values(elev_data)[sel]\n",
    "  \n",
    "  hists[[length(hists) + 1]] <- hist(elev_sel, breaks = bins, plot = FALSE)$counts\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the dates from the SWS product file names to be used as legends in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "labels_wsm <- sapply(files_wsm, function(ele) {\n",
    "  tools::file_path_sans_ext(basename(ele))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, prepare a plot showing the wet snow extent in relation to the altitude for the full SWS time series used as input.\n",
    "\n",
    "Ensure that the legend (from the previous step) and axis labels are added for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data for plotting\n",
    "plot_data <- data.frame()\n",
    "for (i in seq_along(hists)) {\n",
    "  plot_data <- rbind(plot_data, data.frame(\n",
    "    hist = hists[[i]],\n",
    "    elevs = elevs,\n",
    "    label_wsm = substr(labels_wsm[i], 5, 12)\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Plot the data\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "ggplot(plot_data, aes(x = hist, y = elevs, color = label_wsm)) +\n",
    "  geom_line() +\n",
    "  labs(\n",
    "    title = \"\",\n",
    "    x = \"Number of pixels\",\n",
    "    y = \"Altitude [m a.s.l.]\",\n",
    "    color = \"WSM Label\"\n",
    "  ) +\n",
    "  scale_x_continuous(breaks = seq(0, 20000, by = 2000), limits = c(0, 20000)) +\n",
    "  scale_y_continuous(breaks = seq(0, max(plot_data$elevs), by = 200)) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    legend.position = \"right\",\n",
    "    axis.text = element_text(size = 14),\n",
    "    axis.title = element_text(size = 16)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53547cf",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "><span style = \"font-family:Verdana; font-size:0.7em\">Copyright © <font color='darkblue'>2022</font>, by ENVEO IT GmbH.</span>  \n",
    "<span style = \"font-family:Verdana; font-size:0.7em\">Contributors: Lars Keuris,  Gabriele Schwaizer</span>  \n",
    "<span style = \"font-family:Verdana; font-size:0.7em\">URL: www.enveo.at</span> \n",
    "***\n",
    "<p style = \"font-family:Verdana; font-size:0.7em; line-height:0.5\">Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files, to use the Software without restriction.</p>  \n",
    "<p style = \"font-family:Verdana; font-size:0.7em; line-height:1.15; text-align:justify\">THE SOFTWARE IS PROVIDED AS IS, WITHOUT WARRANTY OF ANYKIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. <b>IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DIRECT INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</b></p>\n",
    "\n",
    "*** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
